P8105_HW5_TEM2171
================
Teresa Moore
2023-11-15

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

# PROBLEM 2

Create a tidy dataframe containing data from all participants, including
the subject ID, arm, and observations over time:

Make a spaghetti plot showing observations on each subject over time,
and comment on differences between groups:

``` r
all_participants_tidy_df |> 
  ggplot(aes(x = week, y = outcome, group = subj, color = group)) + geom_path() + facet_grid(~group)
```

![](p8105_hw_5_tem2171_files/figure-gfm/unnamed-chunk-1-1.png)<!-- -->

For the control arm, the outcomes on average stay the same while for the
experimental arm, we see on average an increaase in the outcomes.

\#PROBLEM 3

``` r
n <- 30
sigma <- 5
alpha <- 0.05
num_simulations <- 5000
```

``` r
simulation_t_test = function(mu) {
  simulation_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )

output = simulation_data |>
  t.test() |>
  broom::tidy() |>
  select(estimate, p.value)

}
```

``` r
simulation_results = expand_grid(
  mu_df = c(0, 1, 2, 3, 4, 5, 6),
  iter = 1:num_simulations
) |>
  mutate(
    estimate = map(mu_df, simulation_t_test)
  ) |>
  unnest(estimate)
```

Make a plot showing the proportion of times the null was rejected (the
power of the test) on the y axis and the true value of μ on the x axis.
Describe the association between effect size and power

``` r
simulation_results |>
  group_by(mu_df) |>
  summarize(
    proportion = sum(p.value<alpha)/num_simulations
  ) |>
  ggplot(aes(x=mu_df, y=proportion)) + geom_line()
```

![](p8105_hw_5_tem2171_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->
As the true value of mu increases, the proportion of times the null was
rehejected also increases. There is a higher rate of increase in
proportion between mu values 1 and 3, before it levels out to 100% at
mu= 4.

a plot showing the average estimate of μ̂ on the y axis and the true
value of μ on the x axis. Make a second plot (or overlay on the first)
the average estimate of μ̂ only in samples for which the null was
rejected on the y axis and the true value of μ on the x axis:

``` r
true_df = simulation_results |>
  group_by(mu_df) |>
  summarize(
    mean_mu = mean(estimate)
  )

rej_df = simulation_results |>
  filter(p.value < alpha) |>
  group_by(mu_df) |>
  summarize(
    mean_mu = mean(estimate)
  )

ggplot(true_df, aes(x=mu_df, y=mean_mu)) + 
  geom_line() +
  geom_line(data=rej_df, color="green")
```

![](p8105_hw_5_tem2171_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

The sample average of μ̂ across tests for which the null is rejected is
no approximately equal to the true value of μ for lower values of mu
between 0-4. Above 4, it is approximately equal.
